#ENV["MOCHA_USE_CUDA"] = "true"
using Mocha
#using PyCall

backend = CPUBackend()
init(backend)

base = "/home/jabyte/Thesis/Training_Set/november/malware"
exp_dir = "$base/snapshots-malware"

data_tr_layer = HDF5DataLayer(name="data-train", source="$base/data/train.txt", batch_size=100, shuffle=true)
data_tt_layer = HDF5DataLayer(name="data-test", source="$base/data/test.txt", batch_size=100)

conv1_layer = ConvolutionLayer(name="conv1", n_filter=32, kernel=(5,5), pad=(2,2), stride=(1,1), filter_init=GaussianInitializer(std=0.0001), bottoms=[:data], tops=[:conv1])
pool1_layer = PoolingLayer(name="pool1", kernel=(3,3), stride=(2,2), neuron=Neurons.ReLU(), bottoms=[:conv1], tops=[:pool1])
norm1_layer = LRNLayer(name="norm1", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(), bottoms=[:pool1], tops=[:norm1])

conv2_layer = ConvolutionLayer(name="conv2", n_filter=32, kernel=(5,5), pad=(2,2), stride=(1,1), filter_init=GaussianInitializer(std=0.01), bottoms=[:norm1], tops=[:conv2], neuron=Neurons.ReLU())
pool2_layer = PoolingLayer(name="pool2", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(), bottoms=[:conv2], tops=[:pool2])
norm2_layer = LRNLayer(name="norm2", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(), bottoms=[:pool2], tops=[:norm2])

conv3_layer = ConvolutionLayer(name="conv3", n_filter=64, kernel=(5,5), pad=(2,2), stride=(1,1), filter_init=GaussianInitializer(std=0.01), bottoms=[:norm2], tops=[:conv3], neuron=Neurons.ReLU())
pool3_layer = PoolingLayer(name="pool3", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(), bottoms=[:conv3], tops=[:pool3])
ip1_layer   = InnerProductLayer(name="ip1", output_dim=10, weight_init=GaussianInitializer(std=0.01), weight_regu=L2Regu(250), bottoms=[:pool3], tops=[:ip1])

loss_layer  = SoftmaxLossLayer(name="softmax", bottoms=[:ip1, :label])
acc_layer   = AccuracyLayer(name="accuracy", bottoms=[:ip1, :label])

common_layers = [conv1_layer, pool1_layer, norm1_layer, conv2_layer, pool2_layer, norm2_layer, conv3_layer, pool3_layer, ip1_layer]

net = Net("Malware_Training", backend, [data_tr_layer, common_layers..., loss_layer])

lr_policy = LRPolicy.Staged(
  (60000, LRPolicy.Fixed(0.001)),
  (5000, LRPolicy.Fixed(0.0001)),
  (5000, LRPolicy.Fixed(0.00001)),
)
method = SGD()
solver_params = make_solver_parameters(method, max_iter=40000,regu_coef=0.004, mom_policy=MomPolicy.Fixed(0.9), lr_policy=lr_policy, load_from="snapshots")
solver = Solver(method, solver_params)

setup_coffee_lounge(solver, save_into="$exp_dir/malware_statistics.jld", every_n_iter=1000)

# report training progress every 200 iterations
add_coffee_break(solver, TrainingSummary(), every_n_iter=100)

# save snapshots every 5000 iterations
add_coffee_break(solver, Snapshot("snapshots"), every_n_iter=4000)

# show performance on test data every 1000 iterations
test_net = Net("Malware Classification", backend, [data_tt_layer, common_layers..., acc_layer])
add_coffee_break(solver, ValidationPerformance(test_net), every_n_iter=500)

solve(solver, net)

destroy(net)
destroy(test_net)
shutdown(backend)
